{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7835173d-34c5-42a8-869d-afdbcfadead9",
   "metadata": {},
   "source": [
    "用22年所有数据进行训练来预测24年的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718e43b-ca26-4678-9150-a18d31ad4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理2022年数据...\n",
      "  光强数据量: 112\n",
      "  物种数据量: 11178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 定义处理数据的函数\n",
    "def process_data(light_file, species_file):\n",
    "    # 读取数据\n",
    "    light_data = pd.read_csv(light_file)\n",
    "    species_data = pd.read_csv(species_file)\n",
    "    \n",
    "    # 数据清理\n",
    "    light_data['latitude'] = pd.to_numeric(light_data['latitude'])\n",
    "    light_data['longitude'] = pd.to_numeric(light_data['longitude'])\n",
    "    species_data['latitude'] = pd.to_numeric(species_data['latitude'])\n",
    "    species_data['longitude'] = pd.to_numeric(species_data['longitude'])\n",
    "    light_data['nsb'] = pd.to_numeric(light_data['nsb'])\n",
    "    \n",
    "    # 打印原始数据量\n",
    "    print(f\"  光强数据量: {len(light_data)}\")\n",
    "    print(f\"  物种数据量: {len(species_data)}\")\n",
    "    \n",
    "    species_with_light = []\n",
    "    \n",
    "    for _, species_row in species_data.iterrows():\n",
    "        nearby_stations = find_nearby_light_stations(species_row, light_data)\n",
    "        if nearby_stations:\n",
    "            avg_nsb = sum(station['nsb'] for station in nearby_stations) / len(nearby_stations)\n",
    "            species_with_light.append({\n",
    "                'scientific': species_row['scientific'],\n",
    "                'month': species_row['month'],\n",
    "                'gno': species_row['gno'],\n",
    "                'nsb': avg_nsb,\n",
    "                'stations': [s['location_id'] for s in nearby_stations]\n",
    "            })\n",
    "        else:\n",
    "            species_with_light.append({\n",
    "                'scientific': species_row['scientific'],\n",
    "                'month': species_row['month'],\n",
    "                'gno': species_row['gno'],\n",
    "                'nsb': None,\n",
    "                'stations': []\n",
    "            })\n",
    "    \n",
    "    result_df = pd.DataFrame(species_with_light)\n",
    "    \n",
    "    # 确保所有年份的物种ID一致\n",
    "    global species_to_id\n",
    "    if 'species_to_id' not in globals():\n",
    "        species_to_id = {scientific: idx + 1 for idx, scientific in enumerate(result_df['scientific'].unique())}\n",
    "    \n",
    "    result_df['species_id'] = result_df['scientific'].map(species_to_id)\n",
    "    \n",
    "    # 删除不需要的列\n",
    "    columns_to_drop = []\n",
    "    result_df = result_df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # 添加物种类别\n",
    "    result_df['category'] = result_df['species_id'].apply(get_species_category)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371\n",
    "    return c * r\n",
    "\n",
    "def find_nearby_light_stations(species_row, light_data):\n",
    "    nearby_stations = []\n",
    "    for _, light_row in light_data.iterrows():\n",
    "        if light_row['month'] == species_row['month']:\n",
    "            dist = haversine_distance(\n",
    "                species_row['latitude'], species_row['longitude'],\n",
    "                light_row['latitude'], light_row['longitude']\n",
    "            )\n",
    "            if dist < 2:\n",
    "                nearby_stations.append({\n",
    "                    'location_id': light_row['location_id'],\n",
    "                    'distance': dist,\n",
    "                    'nsb': light_row['nsb']\n",
    "                })\n",
    "    return nearby_stations\n",
    "\n",
    "# 物种分类\n",
    "birds = [8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 29, 30, 31, 37, 38, 39, 40, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 70, 71, 72, 84, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 104, 113, 114, 117, 119, 123, 124, 125, 130, 131, 132, 134, 135, 139, 143, 145, 147, 148, 153, 154, 157, 158, 159, 162, 171, 176, 177, 179, 180, 181, 187, 188, 189, 190, 194, 195, 196, 197, 201, 202, 210, 222, 223, 224, 225, 226, 228, 229, 230, 231, 233, 236, 237, 242, 243, 251, 252, 260, 261, 262, 271, 276, 277, 283, 284, 287, 294, 308, 309, 318, 325, 326, 327, 328, 329, 330, 337, 343, 344, 345, 346, 349, 362, 363, 378, 385, 386, 387, 388, 392, 393, 394, 395, 398, 420, 427, 428, 446, 447, 449, 450, 474, 475, 479, 480, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 510, 511, 512, 524, 525, 543, 544, 545, 546, 547, 548, 551, 552, 553, 563, 564, 565, 578, 580, 588, 595, 596, 597, 600, 601, 604, 605, 606, 609, 610, 611, 612, 613, 614, 617, 622, 632, 633, 636, 637, 645, 649, 650, 651, 652, 653, 654, 655, 660, 661, 662, 663, 664, 668, 669, 671, 672, 678, 690, 691]\n",
    "mammals = [79, 83, 100, 149, 161, 272, 273, 278, 279, 296, 352, 370, 378, 379, 380, 381, 391, 399, 400, 401, 449, 526, 562, 570, 571, 572, 579, 618, 619, 665, 666, 677]\n",
    "reptiles = [65, 85, 101, 160, 215, 227, 234, 265, 266, 267, 268, 295, 302, 303, 353, 354, 425, 431, 432, 508, 509, 533, 549, 550, 558, 566, 583, 584, 589, 593, 629, 647, 648, 659]\n",
    "amphibians = [33, 186, 221, 280, 281, 289, 319, 320, 331, 340, 375, 376, 377, 424, 465, 507, 559, 620]\n",
    "fish = [5, 6, 7, 13, 28, 32, 48, 75, 76, 77, 105, 120, 121, 122, 136, 140, 141, 151, 163, 191, 218, 219, 220, 239, 241, 263, 264, 269, 275, 292, 293, 341, 350, 351, 389, 390, 434, 435, 445, 471, 481, 513, 534, 539, 540, 568, 569, 581, 582, 591, 627, 628, 635, 646, 676, 679, 680]\n",
    "butterflies_moths = [1, 2, 15, 22, 23, 34, 35, 56, 57, 58, 59, 60, 61, 62, 73, 74, 78, 86, 87, 102, 103, 106, 107, 108, 109, 111, 112, 115, 126, 127, 128, 129, 133, 154, 155, 156, 165, 166, 169, 170, 172, 173, 182, 183, 184, 193, 200, 207, 208, 209, 211, 212, 213, 254, 255, 256, 259, 274, 282, 285, 290, 291, 297, 299, 310, 311, 312, 313, 314, 315, 316, 317, 321, 323, 324, 333, 334, 335, 336, 338, 339, 357, 360, 361, 367, 368, 369, 384, 396, 397, 402, 403, 407, 408, 409, 410, 411, 417, 423, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 472, 473, 476, 483, 484, 502, 503, 505, 515, 516, 517, 521, 522, 523, 527, 528, 531, 561, 573, 577, 594, 602, 603, 615, 621, 623, 624, 625, 626, 630, 631, 640, 641, 642, 658, 667, 673, 674, 681, 682, 683, 684, 685, 686, 687, 688, 689]\n",
    "dragonflies_damselflies = [14, 26, 27, 36, 41, 42, 43, 63, 80, 82, 88, 94, 116, 142, 144, 150, 182, 185, 198, 203, 249, 250, 257, 258, 301, 305, 332, 355, 356, 359, 360, 365, 383, 404, 405, 412, 413, 414, 439, 440, 441, 442, 443, 451, 462, 463, 464, 529, 530, 532, 535, 536, 537, 538, 541, 573, 574, 575, 576, 590, 592, 638, 639, 643, 644, 656, 657, 670, 692, 693, 694]\n",
    "fireflies_beetles = [51, 174, 175, 347, 348, 544, 545, 554, 555, 556, 557, 567, 607, 675]\n",
    "other_invertebrates = [235, 270, 421, 422, 468, 469, 470, 585, 586]\n",
    "\n",
    "def get_species_category(species_id):\n",
    "    if species_id in birds:\n",
    "        return 1\n",
    "    elif species_id in mammals:\n",
    "        return 2\n",
    "    elif species_id in reptiles:\n",
    "        return 3\n",
    "    elif species_id in amphibians:\n",
    "        return 4\n",
    "    elif species_id in fish:\n",
    "        return 5\n",
    "    elif species_id in butterflies_moths:\n",
    "        return 6\n",
    "    elif species_id in dragonflies_damselflies:\n",
    "        return 7\n",
    "    elif species_id in fireflies_beetles:\n",
    "        return 8\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "def add_interaction_terms(df, category_dummies, stations_dummies, degree):\n",
    "    if degree >= 1:\n",
    "        df['nsb'] = df['nsb']\n",
    "    if degree >= 2:\n",
    "        df['nsb^2'] = df['nsb'] ** 2\n",
    "        for c in category_dummies.columns:\n",
    "            for s in stations_dummies.columns:\n",
    "                df[f'{c}*{s}'] = df[c] * df[s]\n",
    "                df[f'nsb*{c}'] = df['nsb'] * df[c]\n",
    "                df[f'nsb*{s}'] = df['nsb'] * df[s]\n",
    "                df[f'nsb^2*{c}'] = df['nsb^2'] * df[c]\n",
    "                df[f'nsb^2*{s}'] = df['nsb^2'] * df[s]\n",
    "                df[f'nsb^2*{c}*{s}'] = df['nsb^2'] * df[c] * df[s]\n",
    "                df[f'nsb*{c}*{s}'] = df['nsb'] * df[c] * df[s]\n",
    "    if degree >= 3:\n",
    "        df['nsb^3'] = df['nsb'] ** 3\n",
    "        for c in category_dummies.columns:\n",
    "            for s in stations_dummies.columns:\n",
    "                df[f'nsb^3*{c}'] = df['nsb^3'] * df[c]\n",
    "                df[f'nsb^3*{s}'] = df['nsb^3'] * df[s]\n",
    "                df[f'nsb^3*{c}*{s}'] = df['nsb^3'] * df[c] * df[s]\n",
    "    if degree >= 4:\n",
    "        df['nsb^4'] = df['nsb'] ** 4\n",
    "        for c in category_dummies.columns:\n",
    "            for s in stations_dummies.columns:\n",
    "                df[f'nsb^4*{c}'] = df['nsb^4'] * df[c]\n",
    "                df[f'nsb^4*{s}'] = df['nsb^4'] * df[s]\n",
    "                df[f'nsb^4*{c}*{s}'] = df['nsb^4'] * df[c] * df[s]\n",
    "    if degree >= 5:\n",
    "        df['nsb^5'] = df['nsb'] ** 5\n",
    "        for c in category_dummies.columns:\n",
    "            for s in stations_dummies.columns:\n",
    "                df[f'nsb^5*{c}'] = df['nsb^5'] * df[c]\n",
    "                df[f'nsb^5*{s}'] = df['nsb^5'] * df[s]\n",
    "                df[f'nsb^5*{c}*{s}'] = df['nsb^5'] * df[c] * df[s]\n",
    "    return df\n",
    "\n",
    "# 处理各年份数据\n",
    "print(\"正在处理2022年数据...\")\n",
    "data_2022 = process_data('/Users/hansen/Desktop/MATH3836proj/香港物种数据/2022年光强.csv', \n",
    "                         '/Users/hansen/Desktop/MATH3836proj/香港物种数据/2022年物种_最终版.csv')\n",
    "print(\"正在处理2024年数据...\")\n",
    "data_2024 = process_data('/Users/hansen/Desktop/MATH3836proj/香港物种数据/2024年光强.csv', \n",
    "                         '/Users/hansen/Desktop/MATH3836proj/香港物种数据/2024年物种_最终版.csv')\n",
    "\n",
    "# 筛选有效数据\n",
    "valid_data_2022 = data_2022[data_2022['nsb'].notna()].reset_index(drop=True)\n",
    "valid_data_2024 = data_2024[data_2024['nsb'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"2022年有效数据量: {len(valid_data_2022)}\")\n",
    "print(f\"2024年有效数据量: {len(valid_data_2024)}\")\n",
    "\n",
    "# 打印各年份的物种类别分布\n",
    "for year, data in [('2022', valid_data_2022), ('2024', valid_data_2024)]:\n",
    "    print(f\"\\n{year}年物种类别分布:\")\n",
    "    print(data['category'].value_counts().sort_index())\n",
    "\n",
    "# 合并所有年份的数据，以确保相同的特征集\n",
    "all_data = pd.concat([valid_data_2022, valid_data_2024], axis=0)\n",
    "all_category_dummies = pd.get_dummies(all_data['category'], prefix='category')\n",
    "all_stations_dummies = pd.get_dummies(all_data['stations'].apply(lambda x: x[0] if x else None), prefix='station')\n",
    "\n",
    "# 为每个年份的数据添加相同的哑变量\n",
    "def prepare_data_with_dummies(valid_data, all_category_dummies, all_stations_dummies):\n",
    "    # 创建该年份的哑变量\n",
    "    category_dummies = pd.get_dummies(valid_data['category'], prefix='category')\n",
    "    stations_dummies = pd.get_dummies(valid_data['stations'].apply(lambda x: x[0] if x else None), prefix='station')\n",
    "    \n",
    "    # 添加缺失的列\n",
    "    for col in all_category_dummies.columns:\n",
    "        if col not in category_dummies.columns:\n",
    "            category_dummies[col] = 0\n",
    "    \n",
    "    for col in all_stations_dummies.columns:\n",
    "        if col not in stations_dummies.columns:\n",
    "            stations_dummies[col] = 0\n",
    "    \n",
    "    # 确保列的顺序一致\n",
    "    category_dummies = category_dummies[all_category_dummies.columns]\n",
    "    stations_dummies = stations_dummies[all_stations_dummies.columns]\n",
    "    \n",
    "    return pd.concat([valid_data.reset_index(drop=True), \n",
    "                     category_dummies.reset_index(drop=True), \n",
    "                     stations_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "valid_data_2022_with_dummies = prepare_data_with_dummies(valid_data_2022, all_category_dummies, all_stations_dummies)\n",
    "valid_data_2024_with_dummies = prepare_data_with_dummies(valid_data_2024, all_category_dummies, all_stations_dummies)\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    \"Ridge\": Ridge,  # 使用类，而不是实例\n",
    "}\n",
    "\n",
    "# 初始化结果存储\n",
    "results = {}\n",
    "\n",
    "# 对于每个多项式度数\n",
    "for degree in range(1, 6):\n",
    "    print(f\"\\n正在处理多项式次数 {degree}...\")\n",
    "    \n",
    "    # 添加交互项\n",
    "    train_data = add_interaction_terms(valid_data_2022_with_dummies.copy(), \n",
    "                                      all_category_dummies, \n",
    "                                      all_stations_dummies, \n",
    "                                      degree)\n",
    "    \n",
    "    test_data_2024 = add_interaction_terms(valid_data_2024_with_dummies.copy(), \n",
    "                                         all_category_dummies, \n",
    "                                         all_stations_dummies, \n",
    "                                         degree)\n",
    "    \n",
    "    # 选择特征\n",
    "    numeric_columns = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'gno' in numeric_columns:\n",
    "        numeric_columns.remove('gno')\n",
    "    \n",
    "    # 确保所有数据集有相同的特征列\n",
    "    common_features = list(set(numeric_columns).intersection(\n",
    "                        set(test_data_2024.select_dtypes(include=[np.number]).columns)))\n",
    "    \n",
    "    # 移除'gno'如果它在common_features中\n",
    "    if 'gno' in common_features:\n",
    "        common_features.remove('gno')\n",
    "    \n",
    "    print(f\"使用 {len(common_features)} 个共同特征进行训练和测试\")\n",
    "    \n",
    "    # 准备训练数据\n",
    "    X_train = train_data[common_features]\n",
    "    y_train = train_data['gno']\n",
    "    \n",
    "    # 检查并处理NaN值\n",
    "    nan_count = X_train.isna().sum().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"训练数据中有 {nan_count} 个NaN值，将使用均值填充\")\n",
    "    \n",
    "    # 准备2024年测试数据\n",
    "    X_test = test_data_2024[common_features]\n",
    "    y_test = test_data_2024['gno']\n",
    "    \n",
    "    # 检查并处理NaN值\n",
    "    nan_count = X_test.isna().sum().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"2024年测试数据中有 {nan_count} 个NaN值，将使用均值填充\")\n",
    "    \n",
    "    for name, model_class in models.items():\n",
    "        print(f\"\\n使用 {name} 模型...\")\n",
    "        \n",
    "        # 创建模型实例\n",
    "        model = model_class(alpha=1.0)\n",
    "        \n",
    "        # 创建填充器和标准化器\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # 填充训练数据中的缺失值\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        \n",
    "        # 标准化训练数据\n",
    "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "        \n",
    "        # 训练模型\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 在训练集上评估模型\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        \n",
    "        # 填充测试数据中的缺失值\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "        \n",
    "        # 标准化测试数据\n",
    "        X_test_scaled = scaler.transform(X_test_imputed)\n",
    "        \n",
    "        # 在测试集上评估模型\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # 存储结果\n",
    "        if name not in results:\n",
    "            results[name] = {\n",
    "                'degree': [],\n",
    "                'r2_train': [], 'rmse_train': [],\n",
    "                'r2_test': [], 'rmse_test': []\n",
    "            }\n",
    "        \n",
    "        results[name]['degree'].append(degree)\n",
    "        results[name]['r2_train'].append(r2_train)\n",
    "        results[name]['rmse_train'].append(rmse_train)\n",
    "        results[name]['r2_test'].append(r2_test)\n",
    "        results[name]['rmse_test'].append(rmse_test)\n",
    "        \n",
    "        print(f\"  多项式次数 {degree}：\")\n",
    "        print(f\"    2022年(训练集) R²: {r2_train:.4f}, RMSE: {rmse_train:.4f}\")\n",
    "        print(f\"    2024年(测试集) R²: {r2_test:.4f}, RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "# 可视化结果 - 使用英文标签\n",
    "for name, result in results.items():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # R² 值比较\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(result['degree'], result['r2_train'], marker='o', label='2022 (Training Set)')\n",
    "    plt.plot(result['degree'], result['r2_test'], marker='^', label='2024 (Test Set)')\n",
    "    plt.title(f'{name} Model R² Values on Different Datasets')\n",
    "    plt.xlabel('Polynomial Degree')\n",
    "    plt.ylabel('R² Value')\n",
    "    plt.xticks(result['degree'])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # RMSE 值比较\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(result['degree'], result['rmse_train'], marker='o', label='2022 (Training Set)')\n",
    "    plt.plot(result['degree'], result['rmse_test'], marker='^', label='2024 (Test Set)')\n",
    "    plt.title(f'{name} Model RMSE Values on Different Datasets')\n",
    "    plt.xlabel('Polynomial Degree')\n",
    "    plt.ylabel('RMSE Value')\n",
    "    plt.xticks(result['degree'])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name}_model_results.png')\n",
    "    plt.show()\n",
    "\n",
    "# 打印最佳模型结果\n",
    "for name, result in results.items():\n",
    "    best_degree_train = result['degree'][np.argmax(result['r2_train'])]\n",
    "    best_degree_test = result['degree'][np.argmax(result['r2_test'])]\n",
    "    \n",
    "    print(f\"\\n{name} 模型结果总结:\")\n",
    "    print(f\"2022年训练集最佳多项式次数: {best_degree_train}, R²: {max(result['r2_train']):.4f}, RMSE: {min(result['rmse_train']):.4f}\")\n",
    "    print(f\"2024年测试集最佳多项式次数: {best_degree_test}, R²: {max(result['r2_test']):.4f}, RMSE: {min(result['rmse_test']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8374add-9ec1-4abc-b89e-09e83a2d944c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
